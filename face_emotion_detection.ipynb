{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,optimizers\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_270(m):\n",
    "    N = len(m)\n",
    "    ret = [[0] * N for _ in range(N)]\n",
    "\n",
    "    for r in range(N):\n",
    "        for c in range(N):\n",
    "            ret[N-1-c][r] = m[r][c]\n",
    "    return np.array(ret)\n",
    "\n",
    "def rotate_90(m):\n",
    "    N = len(m)\n",
    "    ret = [[0] * N for _ in range(N)]\n",
    "    # 왜 'ret = [[0] * N] * N'과 같이 하지 않는지 헷갈리시면 연락주세요.\n",
    "\n",
    "    for r in range(N):\n",
    "        for c in range(N):\n",
    "            ret[c][N-1-r] = m[r][c]\n",
    "    return np.array(ret)\n",
    "def parse_data(data):\n",
    "    image_array = np.zeros(shape=(len(data), 48, 48, 1))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48, 1))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bmllab/bml_pjh/face_data'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/bmllab/bml_pjh/face_data')\n",
    "data=pd.read_csv('fer2013.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#angry와 disgust표정 거의 똑같아 보여서 하나의 표정으로\n",
    "for i in range(len(data['Usage'])):\n",
    "    if data.iloc[i,0]==1:\n",
    "        data.iloc[i,0]=0\n",
    "    elif data.iloc[i,0]==3:\n",
    "        data.iloc[i,0]=1\n",
    "    elif data.iloc[i,0]==4:\n",
    "        data.iloc[i,0]=2\n",
    "    elif data.iloc[i,0]==5:\n",
    "        data.iloc[i,0]=3\n",
    "    elif data.iloc[i,0]==6:\n",
    "        data.iloc[i,0]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fear이 오히려 학습에 방해를 줄거같다는 판단하에 drop\n",
    "data.drop(data.loc[data['emotion']==2].index,axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19782, 48, 48, 1)\n",
      "(19782,)\n"
     ]
    }
   ],
   "source": [
    "train_imgs, train_lbls = parse_data(data[data[\"Usage\"] == \"Training\"])\n",
    "val_imgs, val_lbls = parse_data(data[data[\"Usage\"] == \"PrivateTest\"])\n",
    "test_imgs, test_lbls = parse_data(data[data[\"Usage\"] == \"PublicTest\"])\n",
    "print(train_imgs.shape)\n",
    "print(train_lbls.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs=list(train_imgs)\n",
    "train_lbls=list(train_lbls)\n",
    "for i in range(len(data[data[\"Usage\"] == \"Training\"])):\n",
    "    train_imgs.append(rotate_90(train_imgs[i]))\n",
    "    train_imgs.append(rotate_270(train_imgs[i]))\n",
    "    train_lbls.append(train_lbls[i])\n",
    "    train_lbls.append(train_lbls[i])\n",
    "    \n",
    "train_imgs=np.array(train_imgs)\n",
    "train_lbls=np.array(train_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59346, 48, 48, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59346,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lbls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model build start\n",
      "model build complete\n",
      "Train on 59346 samples, validate on 2467 samples\n",
      "Epoch 1/20\n",
      "59346/59346 [==============================] - 1278s 22ms/sample - loss: 1.1568 - sparse_categorical_accuracy: 0.4930 - val_loss: 1.2828 - val_sparse_categorical_accuracy: 0.4868\n",
      "Epoch 2/20\n",
      "59346/59346 [==============================] - 1270s 21ms/sample - loss: 0.8428 - sparse_categorical_accuracy: 0.6576 - val_loss: 0.9267 - val_sparse_categorical_accuracy: 0.6307\n",
      "Epoch 3/20\n",
      " 1760/59346 [..............................] - ETA: 20:44 - loss: 0.7001 - sparse_categorical_accuracy: 0.7250"
     ]
    }
   ],
   "source": [
    "train_x=train_imgs/255.0\n",
    "test_x=test_imgs/255.0\n",
    "val_x=val_imgs/255\n",
    "def build_last(input_shape,classes):\n",
    "    inputs=layers.Input(shape=input_shape)\n",
    "    \n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(inputs)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "   \n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "\n",
    "    \n",
    "    x__=layers.Conv2D(64,(3,3),padding='same')(inputs)\n",
    "    x__=layers.BatchNormalization()(x__)\n",
    "    x__=layers.ReLU()(x__)\n",
    "    x_=tf.add(x,x__)\n",
    "    x_=layers.Dropout(0.5)(x_)\n",
    "\n",
    "   \n",
    "    \n",
    "    x=layers.Conv2D(128,(3,3),strides=(2,2))(x_)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "    \n",
    "   \n",
    "    x=layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)    \n",
    "    \n",
    "    x_=layers.Conv2D(128,(3,3),strides=(2,2))(x_)\n",
    "    x_=layers.BatchNormalization()(x_)\n",
    "    x_=layers.ReLU()(x_)\n",
    "    x_=tf.add(x,x_)\n",
    "    x_=layers.Dropout(0.5)(x_)\n",
    "    \n",
    "    x=layers.Conv2D(256,(3,3),strides=(2,2))(x_)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)    \n",
    "    \n",
    "    x=layers.ZeroPadding2D()(x)    \n",
    "    x=layers.Conv2D(256,(3,3))(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)   \n",
    "    \n",
    "    x_=layers.Conv2D(256,(3,3),strides=(2,2))(x_)\n",
    "    x_=layers.BatchNormalization()(x_)\n",
    "    x_=layers.ReLU()(x_)\n",
    "    x_=tf.add(x,x_)\n",
    "    \n",
    "    x=layers.Conv2D(256,(3,3),strides=(2,2))(x_)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)    \n",
    "    \n",
    "    x=layers.ZeroPadding2D()(x)    \n",
    "    x=layers.Conv2D(256,(3,3))(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)   \n",
    "    \n",
    "    x_=layers.Conv2D(256,(3,3),strides=(2,2))(x_)\n",
    "    x_=layers.BatchNormalization()(x_)\n",
    "    x_=layers.ReLU()(x_)\n",
    "    x_=tf.add(x,x_)\n",
    " \n",
    "    \n",
    "    x=layers.GlobalAveragePooling2D()(x_)\n",
    "    \n",
    "    pred=layers.Dense(classes,activation=\"softmax\")(x)\n",
    "    \n",
    "    model=tf.keras.Model(inputs=inputs,outputs=pred)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def build_last2(input_shape,classes):\n",
    "    inputs=layers.Input(shape=input_shape)\n",
    "    \n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(inputs)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "   \n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(64,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "\n",
    "    \n",
    "    x__=layers.Conv2D(64,(3,3),padding='same')(inputs)\n",
    "    x__=layers.BatchNormalization()(x__)\n",
    "    x__=layers.ReLU()(x__)\n",
    "    x_=tf.add(x,x__)\n",
    "    x_=layers.Dropout(0.5)(x_)\n",
    "\n",
    "   \n",
    "    \n",
    "    x=layers.Conv2D(128,(3,3),strides=(2,2))(x_)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)\n",
    "    \n",
    "   \n",
    "    x=layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.Conv2D(128,(3,3),padding='same')(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)    \n",
    "    \n",
    "    x_=layers.Conv2D(128,(3,3),strides=(2,2))(x_)\n",
    "    x_=layers.BatchNormalization()(x_)\n",
    "    x_=layers.ReLU()(x_)\n",
    "    x_=tf.add(x,x_)\n",
    "    x_=layers.Dropout(0.5)(x_)\n",
    "    \n",
    "    x=layers.Conv2D(256,(3,3),strides=(2,2))(x_)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)    \n",
    "    \n",
    "    x=layers.ZeroPadding2D()(x)    \n",
    "    x=layers.Conv2D(256,(3,3))(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)   \n",
    "    \n",
    "    x_=layers.Conv2D(256,(3,3),strides=(2,2))(x_)\n",
    "    x_=layers.BatchNormalization()(x_)\n",
    "    x_=layers.ReLU()(x_)\n",
    "    x_=tf.add(x,x_)\n",
    "    x_=layers.Dropout(0.5)(x_)\n",
    "    \n",
    "    x=layers.Conv2D(256,(3,3),strides=(2,2))(x_)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)    \n",
    "    \n",
    "    x=layers.ZeroPadding2D()(x)    \n",
    "    x=layers.Conv2D(256,(3,3))(x)\n",
    "    x=layers.BatchNormalization()(x)\n",
    "    x=layers.ReLU()(x)   \n",
    "    \n",
    "    x_=layers.Conv2D(256,(3,3),strides=(2,2))(x_)\n",
    "    x_=layers.BatchNormalization()(x_)\n",
    "    x_=layers.ReLU()(x_)\n",
    "    x_=tf.add(x,x_)\n",
    " \n",
    "    \n",
    "    x=layers.GlobalAveragePooling2D()(x_)\n",
    "    \n",
    "    pred=layers.Dense(classes,activation=\"softmax\")(x)\n",
    "    \n",
    "    model=tf.keras.Model(inputs=inputs,outputs=pred)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "class_names=['angry','happy','sad','surprise','neutral']\n",
    "print(\"model build start\")\n",
    "model=build_last(input_shape=(48,48,1), classes=len(class_names))\n",
    "\n",
    "print(\"model build complete\")\n",
    "optimizer=optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "batch_size=80\n",
    "epochs=20\n",
    "\n",
    "model.fit(train_x,train_lbls,batch_size=batch_size,epochs=epochs,validation_data=(val_x,val_lbls))\n",
    "\n",
    "os.chdir(\"/home/bmllab/bml_pjh/face_model\")\n",
    "test_loss,test_acc=model.evaluate(test_x,test_lbls)\n",
    "\n",
    "print(\"test_acc: %f\"%test_acc)\n",
    "\n",
    "model.save(\"emotion_model20210130.h5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
